\section{Methodology}\label{sec:methodology}
The \ac{db2} has \var{entries_db_all} independent recordings from various field investigations throughout the world, and it is the largest of its kind~\cite{FoldvaryLicina2018, db2dryad}.
\Ac{tsv} were collected using a right-here-right-now survey and environmental parameters were measured and logged in the proximity of participants when they completed the survey.
The \ac{db2} only contains data collected by researchers in cross-sectional field studies that have been published in peer-reviewed journals.

\subsection{Data Preparation and Cleaning}\label{subsec:data-processing-and-cleaning}
Not all researchers measured and logged all six parameters needed to calculate the \ac{pmv} and \ac{pmv-ce}.
We, therefore, decided to remove all entries that did not have any of the following variables: \ac{tdb}, \ac{tr}, \ac{rh}, \ac{v}, \ac{clo}, \ac{met}, and \ac{tsv}.
This filtered out approximately \var{entries_db_valid} of the data.
In our analysis, we used the value \ac{v} which is adjusted as a function of \ac{met} and not the air speed measured by the researchers.
This is because both \ac{pmv} formulations use the \ac{v} adjusted as a function of \ac{met} to calculate the \ac{pmv} value.

Both the \gls{55} and \gls{7730} specify a set of applicability limits.
We hence filtered out those data points that did not meet the inclusion criteria of both standards.
The rationale is that the models' accuracy should only be tested within their applicability ranges.
The limits we used are as follows:
\num{10}~$\leq$~\ac{tdb}~$\leq$~\qty{30}{\celsius},
\num{10}~$\leq$~\ac{tr}~$\leq$~\qty{40}{\celsius},
\num{0}~$\leq$~\ac{v}~$\leq$~\qty{1}{\m\per\s},
\num{0}~$\leq$~\ac{clo}~$\leq$~\qty{1.5}{clo},
\num{0}~$\leq$~water vapor partial pressure~$\leq$~\qty{2000}{\pascal},
and \num{1}~$\leq$~\ac{met}~$\leq$~\qty{4}{met}.
These criteria removed an additional \var{entries_db_filtered_by_limit_inputs} datapoints.
Consequently, the final dataset used for the analysis contains \var{entries_db_used} entries.
The adjusted total clothing insulation and relative airspeed, as required by both standards, were used to calculate the \ac{pmv} and \ac{pmv-ce} values.

Fanger and the \gls{7730} state that the \ac{pmv} should only be used when its absolute value is lower than 2~\cite{Fanger1970, iso7730}.
However, since the thermal sensation was measured with a seven-point scale and the \ac{pmv} has no upper or lower boundary, we decided to keep the data that felt within the following ranges $|$\ac{tsv}$|$~$\leq$~\num{3} or $|$\ac{pmv}$|$~$\leq$~\num{3.5}.

In addition, it should also be noted that while all the data included in the \ac{db2} are published in peer-reviewed papers, not all entries were collected using the same methodology.
For example, while both thermal comfort standards recommend measuring \ac{v} at three different heights, this was not always done.
This could introduce a bias in the measurements and, consequently, in the results of the models.
Moreover, since the two \ac{pmv} formulations only differ when \ac{v}~$\geq$~\qty{0.1}{\m\per\s}, we decided to report three sets of results:
\begin{enumerate}[ {}1{)} ]
    \item all the data points with \ac{tdb}, \ac{tr}, \ac{rh}, \ac{v}, \ac{clo}, \ac{met}, and \ac{tsv};
    \item the data points in 1) with \ac{v}~$\geq$~\qty{0.2}{\m\per\s};
    \item the data points in 1) with \ac{v}~$\geq$~\qty{0.2}{\m\per\s} and from those studies that measured air speed at three different heights.
    These results are reported in \ref{sec:analysis-of-the-dataset-with-air-speed-measurements-at-three-heights}.
\end{enumerate}
Comparing the results from these three datasets will allow us to assess the impact of the data quality on the results of the models.
By only including those studies that measured air speed at three different heights, we can reduce the bias introduced by the lack of adherence to the measurement protocol recommended by both standards.
We did not use \qty{0.1}{\m\per\s} as a threshold because the original difference between the two models was \qty{0.2}{\m\per\s} and it was changed to \qty{0.1}{\m\per\s} only in the \gls{55}.
The effect of air movement is perceptible only when the airspeed is sufficiently high to disrupt the body's thermal plume~\cite{zukowska_impact_2012}.
The threshold in the ASHRAE standard was reduced to \qty{0.1}{\m\per\s} to simplify the usability and achieve one threshold for all the air speeds.
In \ref{sec:analysis-of-the-dataset-with-air-speed-measurements-at-three-heights}, we also present the results generated using those entries with \ac{v}~$\geq$~\qty{0.2}{\m\per\s} and from those studies that measured \ac{v} at three different heights.
We have not included these results here, as they are comparable to those presented in this section and lead to the same conclusions.

We used Python to analyze and visualize the results.
The \ac{pmv} results were calculated using the function `pythermalcomfort.models.pmv\_ppd' included in pythermalcomfort v2.8.1 a Python package for thermal comfort calculations~\cite{Tartarini2020a}.
We are committed to reproducible research, hence we have shared the source code and the dataset we used publicly at this URL: \url{https://github.com/FedericoTartarini/paper-pmv-comparison} so other users can test different assumptions.

\subsection{Model Validation}\label{subsec:model-validation}
The \ac{pmv} model was developed to predict the average thermal sensation of a large group of occupants, but it is commonly used both in singly occupied zones and in areas with several hundred people.
We first grouped participants' responses by their \ac{tsv}, and we determined how many of these votes were correctly labelled by the \ac{pmv} and \ac{pmv-ce} models.
This approach is useful for performing an overall assessment of the accuracy of the models, but it introduces an error due to the rounding of both the \ac{pmv}, \ac{pmv-ce}, and \ac{tsv} values.
The latter were sometimes collected using a continuous scale and not a discrete one, in other words, they could take any value in the range from -3.0 to 3.0.

To remove this rounding error, we subtracted the \ac{tsv} value from the \ac{pmv} and \ac{pmv-ce} values.
These differences, also known as bias, quantify the success of the model in predicting \ac{tsv}.
However, on their own, are a low-precision estimate of the overall accuracy of the model~\cite{Humphreys2002}.
These values were then binned using several independent variables (e.g., \ac{tdb}, \ac{v}).
If the \ac{pmv} or \ac{pmv-ce} formulations are bias-free, the distribution of any batch derived from these differences would have a mean value that is zero.
The standard deviation would reflect the combined effect of the people's individual differences, any errors in the model formulation or, in the data collection method (accuracy or precision of the instrumentation used)~\cite{Humphreys2002}.
According to \mycite{Humphreys2002} the model can be considered accurate if the above-mentioned differences are between \num{-0.25} and \num{0.25}.
However, we believe that this range is too narrow since \ac{tsv} is commonly measured using an ordinal scale of integers.
Consequently, we expanded the range to \num{-.5} and \num{0.5}.
This is needed to ensure that each \ac{pmv} value can be matched to a \ac{tsv}.
We are aware that an error of \num{.5} is approximately \qty{7}{\percent} of the total range and ideally, we would want to have the \ac{pmv} to have higher precision, however, this is a necessary limitation introduced by the low resolution of the \ac{tsv} scale.
When the aim is to predict the average thermal sensation of a large group of occupants, binning data by the independent variables is a better representation.
Grouping the participants' responses by their \ac{tsv} mixes people who reported the same \ac{tsv} vote but could have been in different locations and moments of the year and day.

\subsection{Performance Metrics}\label{subsec:performance-metrics}
Simple accuracy is a misleading metric to use to quantify the performance of a classification predictive model that involves an unbalanced dataset~\cite{Chawla2005}.
We then also report the F1 score when determining the performance of the \ac{pmv} and \ac{pmv-ce} in predicting the \ac{tsv}.
The F1 score is the harmonic mean of the precision and sensitivity, where an F1 score reaches its best value at 1 and the worst score at 0.
Precision (also called positive predictive value) is the ratio of true positives over all the positive results obtained from the test. 
Sensitivity (also known as recall or true positive rate) is the ratio of true positive results over all the actual positive cases.
We report three F1 scores in the paper.
The F1-micro score calculates metrics globally by counting the total true positives, false negatives, and false positives.
The F1-macro calculates metrics for each label and finds their unweighted mean.
The F1-weighted calculate metrics for each label and find their average weighted by support (the number of true instances for each label).
For the interpretation of our results, F1-macro is arguably the most important because it is not affected by the unbalanced data distribution (most of the data are for thermal neutrality) and gives equal importance to predicting each of the thermal sensation votes. 
F1-micro is the least important because it is heavily skewed by the unbalance of the classes.